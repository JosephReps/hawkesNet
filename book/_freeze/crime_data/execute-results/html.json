{
  "hash": "1ea58c5d5e1a73e07c1ac1ffbcbed7f6",
  "result": {
    "engine": "knitr",
    "markdown": "\n\n\n# Crime data\n\nSo we have some crime data. The data will not be uploaded, I will just include\nthe code here you can copy and paste to run the data cleaning / model fitting\nyourself.\n\nTo briefly describe it\n\n- `perps.df` contains the `perp`-`perp` edge data.\n\n- `events.df` contains the `event`-`perp` edge data.\n\n## BA-Bipartite Network Specification\n\nRecall under the BA-Bipartite network specification we are **assuming** that marks\nare structured in the following way:\n\n- Nodes have two possible classifications - `event` and `perp`.\n\n- Each mark consists of exactly 1 new `event` node arriving, which connects to \nold `perp` nodes according to the same degree-based weighting as the BA kernel.\n\n- The *number* of `perp` nodes is distributed Poisson(`lambda_new`)\n\nUnder this specification, `perp`-`perp` edges are not allowed to exist (is this\ncorrect?). Hence we can ignore the edges present in the `perps.df` (we will\nrevisit when trying different model specs).\n\n### Data prep\n\nNow, looking at the `perps.df` data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(as.numeric(perps$person_id))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      5  426537  863430  868561 1307976 1742898 \n```\n\n\n:::\n:::\n\n\nIt looks like the `person_id`'s stretch all the way from 5 to 1742898. We will \njust treat these as node ID's. And in order to prevent any clashes, we will just\nprepend \"event_\" on to the `event_id` to use as the node ID's of the event nodes.\n\nFirst converting to long format.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyr)\nlibrary(dplyr)\n\n# Love how easy this is\nlong_df <- events %>%\n  unnest(people) %>%\n  rename(person = people)\n```\n:::\n\n\nNow need to make sure the names don't clash as mentioned above (will prepend \n\"perp_\" to the `perp` ID's aswell just for\nconsistency):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nedges <- long_df %>% \n  mutate(\n    event_id = paste0(\"event_\", event_id),\n    person = paste0(\"perp_\", person)\n    ) %>% \n  rename(\n    i = event_id, # Doesn't matter what order we choose i/j\n    j = person,\n    time = diff_date\n  ) %>% \n  select(i, j, time) %>% \n  distinct() %>%  # The way the original data set was constructed, we end up with\n  filter(time < 5)                  # two identical rows per edge sometimes\n\n# Only considering a small sub net for example \n```\n:::\n\n\nLastly, we need to make sure we include the `perp`-`event` node classification.\n\nThis is easier if we use `make_events()` first, as it will automatically \ngenerate a `nodes` data frame, and then we can just add a column to this.\n\n:::callout-note\nNot sure if I like this manipulation after-the-fact. Wondering how you guys\nprepared your data.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nev <- make_events(edges = edges)\n```\n:::\n\n\nLooks like 14000-ish events, 27000-ish node arrivals, and 19000-ish edges.\n\nNow just add a \"role\" column to `ev$nodes`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nev$nodes$role <- ifelse(\n  grepl(\"event\", ev$nodes$id),\n  \"event\",\n  \"perp\"\n)\n```\n:::\n\n\nAnd we are good to fit.\n\n### Model fitting\n\nOnly gonna consider a SMALL time window, just trying to demonstrate here.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(ev$times < 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 147\n```\n\n\n:::\n:::\n\n\nWe'll set `T_end` = 5.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nparams_bip_init <- list(\n  mu = 1,\n  K = 1,\n  beta = 1,\n  beta_edges = 1,\n  lambda_new = 3.5\n)\n\nfit <- fit_hawkesNet(\n      ev = ev,\n      params_init = params_bip_init,\n      mark_type = \"ba_bip\",\n      debug = T\n    )\n```\n:::\n\n\n\n\n\n\n\n\n\n\n",
    "supporting": [
      "crime_data_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}